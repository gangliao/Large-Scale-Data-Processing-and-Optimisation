## A Brief Survey of Deep Reinforcement Learning

[Introduction of
Reinforcement Learning](http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2017/Lecture/RL%20(v4).pdf)

> Title: A Brief Survey of Deep Reinforcement Learning 

> Conference/Journal: IEEE SP 

> Year: 2017

> Authors: Kai Arulkumaran, Marc Peter Deisenroth, Miles Brundage, Anil Anthony Bharath

### Summary

Deep reinforcement learning -> building autonomous systems with a higher level understanding of the visual world.

The rise of deep learning, relying on the `powerful function approximation` and `representation learning` properties of deep neural networks—has provided us with new tools to overcoming these problems: memory complexity, computational complexity and sample complexity.

The most important property of deep learning is that deep neural networks can automatically find compact low-dimensional representations (features) of high-dimensional data (e.g., images, text and audio). 

Deep learning algorithms within RL defining the field of “deep reinforcement learning” (DRL).


How to play game is not the end goal of DRL. One of the driving forces behind DRL is the vision of creating systems that are capable of learning how to adapt in the real world. It seems likely that in the future, DRL will be an important component in constructing general AI systems. 

1. Deep Q-network

2. trust region policy optimisation

3. asynchronous advantage actor-critic


**Unlike policy gradient methods, which attempt to learn functions which directly map an observation to an action, Q-Learning attempts to learn the value of being in a given state, and taking a specific action there.** from [medium](https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0)

### Cool Ideas


### Questions
